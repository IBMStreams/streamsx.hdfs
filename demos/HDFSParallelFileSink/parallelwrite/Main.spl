// (C) Copyright IBM Corp. 2014  All Rights reserved.         
namespace parallelwrite ;

use com.ibm.streamsx.hdfs::HDFS2FileSink ;
/**
 * Shows how speed up file writing using multiple HDFSFileSinks.
 * 
 * With the older HDFS toolkit, parallelizing writing to HDFS was complicated,
 * involving splmm and a specialized operator.  
 * 
 * With Streams 3.2 and beyond, the @parallel annotation allows for easy parallelization,
 * and the 3.2 java-based HDFS operator means that the specialized splitter is no 
 * longer required for good performance. 
 * 
 * The combination of these two operators means it is very easy to parallelization is 
 * quite simple.  In this example, by default, we use a width of three.  To change 
 * the width, you can set the submission time parameter named width.  For example, to set
 * the width to 5 in distributed mode, add <code>-P width=5</code> to the 
 * submitjob command.  To set the width to 5 in standalone mode, and <code>width=5</code>
 * when you run the standalone application.  
 * 
 * The code below makes use of getChannel() to ensure the that file name written by each of 
 * the sinks will be different.  In this case, with the default width of three, the three files are:
 * * file0of3.txt
 * * file1of3.txt
 * * file2of3.txt
 * 
 */
composite Main
{
	param
		expression<rstring> $baseDir : getSubmissionTimeValue("hadoopDir", "") ;
		expression<uint32> $numTuples : 100u ;
		expression<int32> $numParallelCopies :(int32) getSubmissionTimeValue("width",
			"3") ;
	graph
		stream<rstring data> SourceStream = Beacon()
		{
			logic
				state : mutable uint32 numTuples = 0 ;
				// Eliminate the following line to make the data source run forever

			param
				iterations : $numTuples ;
			output
				SourceStream : data = "This is line number " +(rstring)(numTuples ++) +
					" of " +(rstring) $numTuples ;
		}

		() as localSink = FileSink(SourceStream) {
	          logic
	                onTuple SourceStream :
	                {
	                    printStringLn(data);
	                }

			param file: "write_local.txt";
		}



		// Note the use of getChannel() in the filename.
		@parallel(width = $numParallelCopies)
		() as sink = HDFS2FileSink(SourceStream)
		{
			param
				file : $baseDir + "file" +(rstring) getChannel() + "of" +(rstring)
					$numParallelCopies + ".txt" ;
		}

}
