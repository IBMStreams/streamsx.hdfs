/*******************************************************************************
* Copyright (C) 2014, International Business Machines Corporation
* All Rights Reserved
*******************************************************************************/                        

namespace hdfsexample ;

use com.ibm.streamsx.hdfs::HDFS2FileSource ;
/**
  * The [HDFS2FileSourceSampleLineFormat] demonstrates how you can use the HDFS2FileSink operator
  * to read a file from the Hadoop file system.
  *
  * To build this application, you need to set up the HADOOP_HOME environment variable as follows:
  * * export HADOOP_HOME=<Hadoop installation>
  * 
  * Setup:
  * To run this sample, you will need to copy the input file from the sample's data directory to 
  * the Hadoop File System:
  * 1. At the command line, go to the sample's data directory.
  * 1. Run the following command to copy the file from the data directory to HDFS:
  *   * <HADOOP_HOME>/bin/hadoop fs -copyFromLocal LineFile.txt /user/<userId>
  *
  * To compile and run this sample in Streams Studio:
  * 1. Start Streams Studio
  * 1. In Streams Explorer view, add the "com.ibm.streams.bigdata" toolkit as one of the toolkit locations
  * 1. From the main menu, select File -> Import.
  * 1. Expand IBM Streams Studio
  * 1. Select Sample SPL Application
  * 1. Select this sample from the Import SPL Sample Application dialog
  * 1. Once the sample is imported, wait for the build to finish.  If autobuild is turned off, select resulting project, right click -> Build Project
  * 1. Once the project is built, select the main composite of the sample, right click -> Launch Active Build Config
  *
  * If compiling and running from command line, follow these steps:
  *  1. Create a directory. For example, you can create a directory in your home directory.
  *   * mkdir $HOME/hdfssamples
  *  1. Copy the samples to this directory.
  *   * cp -R $STREAMS_INSTALL/toolkits/com.ibm.streams.bigdata/samples/* $HOME/hdfssamples/
  *  1. Build one of the sample applications. Go to the appropriate subdirectory and run the make. By default, the sample is compiled as a distributed application. If you want to compile the application as a standalone application, run make standalone instead. Run make clean to return the samples back to their original state.
  *  1. Run the sample application. 
  *   * To run the HDFS2FileSourceSampleLineFormat sample application in distributed mode, start your IBM Streams instance, then use the streamtool command to submit the .adl files that were generated during the application build. 
  *    * streamtool submitjob -i <instance_name> output/Distributed/hdfsexample::HDFS2FileSourceSampleLineFormat/hdfsexample.HDFS2FileSourceSampleLineFormat.adl -P hdfsUri="hdfs://<machine_name>:<port>" -P hdfsUser="<user_name>" 
  *   * To run the HDFS2FileSourceSampleLineFormat sample application in standalone mode, issue the command:
  *    * ./output/Standalone/hdfsexample::HDFS2FileSourceSampleLineFormat/bin/standalone hdfsUri="hdfs://<machine_name>:<port>" hdfsUser="<user_name>" 
  *
  * @param hdfsUri URI to HDFS.  If unspecified, the operator expects that the HDFS URI is specified as the fs.defaultFS or fs.default.name property in core-site.xml.
  * @param hdfsUser User to connect to HDFS.  If unspecified the instance owner running the application will be used as the user
  * to log onto the HDFS. Example value: "streamsadmin"
  */
composite HDFS2FileSourceSampleLineFormat
{
	graph
		stream<rstring lines> LineStream = HDFS2FileSource()
		{
			param
				file : "LineInput.txt" ;
		} 

		() as MySink = FileSink(LineStream)
		{
			logic
				onTuple LineStream : 
					printStringLn(lines);
					
			param
				file : "LineSink.txt" ;
				flush : 1u ;
		}

}
