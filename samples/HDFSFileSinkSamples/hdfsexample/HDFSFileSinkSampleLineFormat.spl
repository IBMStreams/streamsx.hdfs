/*******************************************************************************
* Copyright (C) 2014, International Business Machines Corporation
* All Rights Reserved
*******************************************************************************/                             
namespace hdfsexample ;

use com.ibm.streamsx.hdfs::HDFS2FileSink ;

/**
 * The [HDFS2FileSinkSampleLineFormat] composite demonstrates how you can
 * use the HDFS2FileSink operator to write data to a file on the Hadoop File System.
 * 
 * This sample reads the "LineInput.txt" file from data directory.  The content of the
 * file is read in one line at a time and sent to a HDFS2FileSink operator to write
 * the data to the Hadoop File System.  We make use of the "bytesPerFile" optional parameter
 * to break up the output file.  A new file is created when the output file size is
 * approximately 100 bytes.
 *  
 * To build this application, you need to set up the HADOOP_HOME environment variable as follows:
 * * export HADOOP_HOME=<Hadoop installation>
 * 
 * To compile and run this sample in Streams Studio:
 * 1. Start Streams Studio
 * 1. In Streams Explorer view, add the "com.ibm.streams.bigdata" toolkit as one of the toolkit locations
 * 1. From the main menu, select File -> Import.
 * 1. Expand Streams Studio
 * 1. Select Sample SPL Application
 * 1. Select this sample from the Import SPL Sample Application dialog
 * 1. Once the sample is imported, wait for the build to finish.  If autobuild is turned off, select resulting project, right click -> Build Project
 * 1. Once the project is built, select the main composite of the sample, right click -> Launch Active Build Config
 *
 * 
  * To compile and run this sample at the command line:
  *  1. Create a directory. For example, you can create a directory in your home directory.
  *   * mkdir $HOME/hdfssamples
  *  1. Copy the samples to this directory.
  *   * cp -R $STREAMS_INSTALL/toolkits/com.ibm.streams.bigdata/samples/* $HOME/hdfssamples/
  *  1. Build one of the sample applications. Go to the appropriate subdirectory and run the make. By default, the sample is compiled as a distributed application. If you want to compile the application as a standalone application, run make standalone instead. Run make clean to return the samples back to their original state.
  *  1. Run the sample application.  
  *   * To run the HDFS2FileSinkSampleLineFormat sample application in distributed mode, start your IBM Streams instance, then use the streamtool command to submit the .adl files that were generated during the application build.
  *    * streamtool submitjob -i <instance_name> output/Distributed/hdfsexample::HDFS2FileSinkSampleLineFormat/hdfsexample.HDFS2FileSinkSampleLineFormat.adl -P hdfsUri="hdfs://<machine_name>:<port>" -P hdfsUser="<user_name>"
  *   * To run the HDFS2FileSinkSampleLineFormat sample application in standalone mode, issue the command:
  *    * ./output/Standalone/hdfsexample::HDFS2FileSinkSampleLineFormat/bin/standalone hdfsUri="hdfs://<machine_name>:<port>" hdfsUser="<user_name>"
  *
  * @param hdfsUri URI to HDFS. If unspecified, the operator expects that the HDFS URI is specified as the fs.defaultFS or fs.default.name property in core-site.xml.
  * @param hdfsUser User to connect to HDFS.  If unspecified the instance owner running the application will be used as the user
  * to log onto the HDFS. Example value: "streamsadmin"
 */
composite HDFS2FileSinkSampleLineFormat
{
	graph
		// read file "LineInput.txt" from sample's data directory
		stream<rstring lines> LineIn = FileSource()
		{
			param
				file : "LineInput.txt" ;
		}

		// Write content of input file to /user/<userid>/pattern0%FILENUM.txt
		// Each file is about 100 bytes in size.
		() as lineSink1 = HDFS2FileSink(LineIn)
		{
			param
				file : "pattern0%FILENUM.txt" ;
				bytesPerFile : 100l ;
		}

}
