/*******************************************************************************
* Copyright (C) 2014, International Business Machines Corporation
* All Rights Reserved
*******************************************************************************/                              
namespace hdfsexample ;

use com.ibm.streamsx.hdfs::HDFS2FileSink ;

/**
 * The [HDFS2FileSinkSampleTxtFormat] composite demonstrates how to use the HDFS2FileSink operator
 * to write to a file in "txt" format.
 *
 * Contrast from the HDFS2FileSink operator, HDFS2FileSink operator only supports writing in "line" format.
 * If your existing application currently uses the HDFS2FileSink operator to write data out as "txt" format,
 * you will need to modify your application in order to maintain the output format.
 * 
 * To continue writing in "txt" format, you can insert a "Functor" operator before the HDFS2FileSink operator
 * to convert a tuple to a rstring.  The string can then be written out to a file on HDFS as is.
 *
 * To build this application, you need to set up the HADOOP_HOME environment variable as follows:
 * * export HADOOP_HOME=<Hadoop installation>
 * 
 * To compile and run this sample in Streams Studio:
 * 1. Start Streams Studio
 * 1. In Streams Explorer view, add the "com.ibm.streams.bigdata" toolkit as one of the toolkit locations
 * 1. From the main menu, select File -> Import.
 * 1. Expand Streams Studio
 * 1. Select Sample SPL Application
 * 1. Select this sample from the Import SPL Sample Application dialog
 * 1. Once the sample is imported, wait for the build to finish.  If autobuild is turned off, select resulting project, right click -> Build Project
 * 1. Once the project is built, select the main composite of the sample, right click -> Launch Active Build Config
 * 
 * To comple and run this sample at the command line:
 *  1. Create a directory. For example, you can create a directory in your home directory.
 *   * mkdir $HOME/hdfssamples
 *  1. Copy the samples to this directory.
 *   * cp -R $STREAMS_INSTALL/toolkits/com.ibm.streams.bigdata/samples/* $HOME/hdfssamples/
 *  1. Build one of the sample applications. Go to the appropriate subdirectory and run the make. By default, the sample is compiled as a distributed application. If you want to compile the application as a standalone application, run make standalone instead. Run make clean to return the samples back to their original state.
 *  1. Run the sample application. 
 *   * To run the HDFS2FileSinkSampleTxtFormat sample application in distributed mode, start your IBM Streams instance, then use the streamtool command to submit the .adl files that were generated during the application build. 
 *    * streamtool submitjob -i <instance_name> output/Distributed/hdfsexample::HDFS2FileSinkSampleTxtFormat/hdfsexample.HDFS2FileSinkSampleTxtFormat.adl
 *   * To run the HDFS2FileSinkSampleTxtFormat sample application in standalone mode, issue the command:
 *    * ./output/Standalone/hdfsexample::HDFS2FileSinkSampleTxtFormat/bin/standalone
 */
composite HDFS2FileSinkSampleTxtFormat
{
	type
		PersonSchema = int32 id, rstring fname, rstring lname, int32 age,
			rstring gender, float32 score, float64 total ;
	graph

		// input file is read in as "txt" format
		stream<PersonSchema> In = FileSource()
		{
			param
				file : "Input.txt" ;
		}

		// convert tuple to rstring
		stream<rstring PersonSchemString> SingleStringIn = Functor(In)
		{
			output
				SingleStringIn : PersonSchemString =(rstring) In ;
		}

		// write out converted string to file
		() as txtSink = HDFS2FileSink(SingleStringIn)
		{
			param
				file : "txtFile.txt" ;
		}

}
